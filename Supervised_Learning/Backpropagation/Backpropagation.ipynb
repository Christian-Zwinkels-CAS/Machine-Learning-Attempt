{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "This document will explain the code I used to attempt to implement the backpropagation machine learning algorithm.\n",
    "\n",
    "## What is it?\n",
    "Backpropagation is an algorithm that is used in neural networks to learn. It is a form of supervised learning where the user gives it training examples with features and a desired output. The machine can try to predict the output then it will use a mutivariable function in order to calculate the error of each weight and bias. It does this for each training example then it tries to find the minimum of this function (essentially finding out what weights and biases correspond to the lowest error) by using gradient descent. The algorithm starts at the last layer then it goes back one layer at a time to the last layer which is why its called backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "the dataset I used was a simple one which is a XOR gate. It has two inputs and each can either be one or a zero. The output will be zero if both inputs are zeros or ones.\n",
    "\n",
    "|Input|Output|\n",
    "|-----|------|\n",
    "|0, 0 |   0  |\n",
    "|0, 1 |   1  |\n",
    "|1, 0 |   1  |\n",
    "|1, 1 |   0  |\n",
    "\n",
    "This dataset is small which means that during testing I dont have to wait long periods of time just to see how well the program did."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
