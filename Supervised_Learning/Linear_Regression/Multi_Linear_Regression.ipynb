{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Variable Linear Regression\n",
    "In this document I will explain the code I wrote to attempt to implement a multivariable linear regression algorithm. Ill try my best to explain how multivariable linear regression works.\n",
    "## Some notation\n",
    "$ m= $ number of training examples (entries) \\\n",
    "$ n= $ number of features \\\n",
    "$ y= $ column matirx of outputs \\\n",
    "$ x^{i}= $ matrix of input features of the $ i^{th} $ training example \\\n",
    "$ x^{i}_{j}= $ value of feature j in the ith training example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset I used was one from a course on machine learning. It has two features and 47 entries. This dataset is small and that was one of the reasons that I chose it as it will make testing code much quicker. I needed to load the dataset into a format that I could use. I made a function that separated the features and the outputs to two different numpy arrays, and added an extra feature to each entry $ x_0=1 $ which I will get to why in a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openCsv(file):\n",
    "    a = open(file)\n",
    "    b = [row for row in csv.reader(a)]\n",
    "    c = [[b[i][-1]] for i in range(len(b))]\n",
    "    for i in range(len(b)):\n",
    "        del b[i][-1]\n",
    "        b[i].insert(0, 1)\n",
    "    X = np.array(b, dtype=np.float64)\n",
    "    y = np.array(c, dtype=np.float64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = openCsv(\"Data_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic feature scaling was applied in which each value of a feature gets divided by the largest value of the feature column, so all values would be between 0 and 1. $ x_0 $ did not have this process applied. This makes the training process a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max = []\n",
    "for i in range(1, np.size(X, axis=1)):\n",
    "    if i == 1:\n",
    "        y_max = np.max(y)\n",
    "        y /= y_max\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    X_max.append(np.max(X[:, i]))\n",
    "    X[:, i] /= X_max[i - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "The hypothesis function is what is used to make a prediction, letting $ \\theta $ be the parameters and $ X $ matrix of a training example's features (including $ x_0 $).\n",
    "$$\n",
    "\\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} X = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n",
    "$$\n",
    "The function multiplies the transpose of the $ \\theta $ matrix and post multiplies it by the matrix $ X $ which leads to a multivariable linear equation.\n",
    "$$\n",
    "\\theta^T X = \\theta_0 x_0 + \\theta_1 x_1 + \\cdots + \\theta_n x_n\n",
    "$$\n",
    "For this to be compatible with feature scaling we first scale all the features by dividing each feature by the max value of all the features. In the begining its one as we have already applied feature scaling so it will divide by one by when we reverse the feature scaling this will scale them back down. It then has the hypothesis function applied, and this result is multiplied by the maximum value of y which will revert the feature scaling. Inititally this is going to be completely wrong, but thats why we train it. \\\n",
    "Since this is a multivariable function plotting is usually not possible as the graph would most likeley be in dimensions higher than the third one. In this case it will be a 3D plot which is possible but I need to figure out how to implement that and learn how to use pyplot a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.abs(np.random.standard_normal((X.shape[-1], 1)))\n",
    "\n",
    "def hypothethis(data_in):\n",
    "    data_in[1:] / np.max(data_in[1:])\n",
    "    pred = (np.dot(thetas.T, data_in.reshape((len(data_in), 1)))) * np.max(y)\n",
    "    return pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
